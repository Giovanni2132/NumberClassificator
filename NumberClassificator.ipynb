{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Giovanni2132/NumberClassificator/blob/main/NumberClassificator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yT0lTCBeSEAA"
      },
      "source": [
        "Importazione del dataset da openml"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import data_table\n",
        "\n",
        "data_table.enable_dataframe_formatter()"
      ],
      "metadata": {
        "id": "oaBLGjyIoKbI"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypGBpYdmRVr5",
        "outputId": "c400cc6e-36d5-47fb-a006-9b044aa13013"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['data', 'target', 'frame', 'categories', 'feature_names', 'target_names', 'DESCR', 'details', 'url'])\n",
            "{'data':        pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  pixel9  \\\n",
            "0         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
            "1         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
            "2         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
            "3         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
            "4         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
            "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
            "69995     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
            "69996     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
            "69997     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
            "69998     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
            "69999     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
            "\n",
            "       pixel10  ...  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
            "0          0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
            "1          0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
            "2          0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
            "3          0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
            "4          0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
            "...        ...  ...       ...       ...       ...       ...       ...   \n",
            "69995      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
            "69996      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
            "69997      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
            "69998      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
            "69999      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
            "\n",
            "       pixel780  pixel781  pixel782  pixel783  pixel784  \n",
            "0           0.0       0.0       0.0       0.0       0.0  \n",
            "1           0.0       0.0       0.0       0.0       0.0  \n",
            "2           0.0       0.0       0.0       0.0       0.0  \n",
            "3           0.0       0.0       0.0       0.0       0.0  \n",
            "4           0.0       0.0       0.0       0.0       0.0  \n",
            "...         ...       ...       ...       ...       ...  \n",
            "69995       0.0       0.0       0.0       0.0       0.0  \n",
            "69996       0.0       0.0       0.0       0.0       0.0  \n",
            "69997       0.0       0.0       0.0       0.0       0.0  \n",
            "69998       0.0       0.0       0.0       0.0       0.0  \n",
            "69999       0.0       0.0       0.0       0.0       0.0  \n",
            "\n",
            "[70000 rows x 784 columns], 'target': 0        5\n",
            "1        0\n",
            "2        4\n",
            "3        1\n",
            "4        9\n",
            "        ..\n",
            "69995    2\n",
            "69996    3\n",
            "69997    4\n",
            "69998    5\n",
            "69999    6\n",
            "Name: class, Length: 70000, dtype: category\n",
            "Categories (10, object): ['0', '1', '2', '3', ..., '6', '7', '8', '9'], 'frame':        pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  pixel9  \\\n",
            "0         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
            "1         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
            "2         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
            "3         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
            "4         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
            "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
            "69995     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
            "69996     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
            "69997     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
            "69998     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
            "69999     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
            "\n",
            "       pixel10  ...  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
            "0          0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
            "1          0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
            "2          0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
            "3          0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
            "4          0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
            "...        ...  ...       ...       ...       ...       ...       ...   \n",
            "69995      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
            "69996      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
            "69997      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
            "69998      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
            "69999      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
            "\n",
            "       pixel781  pixel782  pixel783  pixel784  class  \n",
            "0           0.0       0.0       0.0       0.0      5  \n",
            "1           0.0       0.0       0.0       0.0      0  \n",
            "2           0.0       0.0       0.0       0.0      4  \n",
            "3           0.0       0.0       0.0       0.0      1  \n",
            "4           0.0       0.0       0.0       0.0      9  \n",
            "...         ...       ...       ...       ...    ...  \n",
            "69995       0.0       0.0       0.0       0.0      2  \n",
            "69996       0.0       0.0       0.0       0.0      3  \n",
            "69997       0.0       0.0       0.0       0.0      4  \n",
            "69998       0.0       0.0       0.0       0.0      5  \n",
            "69999       0.0       0.0       0.0       0.0      6  \n",
            "\n",
            "[70000 rows x 785 columns], 'categories': None, 'feature_names': ['pixel1', 'pixel2', 'pixel3', 'pixel4', 'pixel5', 'pixel6', 'pixel7', 'pixel8', 'pixel9', 'pixel10', 'pixel11', 'pixel12', 'pixel13', 'pixel14', 'pixel15', 'pixel16', 'pixel17', 'pixel18', 'pixel19', 'pixel20', 'pixel21', 'pixel22', 'pixel23', 'pixel24', 'pixel25', 'pixel26', 'pixel27', 'pixel28', 'pixel29', 'pixel30', 'pixel31', 'pixel32', 'pixel33', 'pixel34', 'pixel35', 'pixel36', 'pixel37', 'pixel38', 'pixel39', 'pixel40', 'pixel41', 'pixel42', 'pixel43', 'pixel44', 'pixel45', 'pixel46', 'pixel47', 'pixel48', 'pixel49', 'pixel50', 'pixel51', 'pixel52', 'pixel53', 'pixel54', 'pixel55', 'pixel56', 'pixel57', 'pixel58', 'pixel59', 'pixel60', 'pixel61', 'pixel62', 'pixel63', 'pixel64', 'pixel65', 'pixel66', 'pixel67', 'pixel68', 'pixel69', 'pixel70', 'pixel71', 'pixel72', 'pixel73', 'pixel74', 'pixel75', 'pixel76', 'pixel77', 'pixel78', 'pixel79', 'pixel80', 'pixel81', 'pixel82', 'pixel83', 'pixel84', 'pixel85', 'pixel86', 'pixel87', 'pixel88', 'pixel89', 'pixel90', 'pixel91', 'pixel92', 'pixel93', 'pixel94', 'pixel95', 'pixel96', 'pixel97', 'pixel98', 'pixel99', 'pixel100', 'pixel101', 'pixel102', 'pixel103', 'pixel104', 'pixel105', 'pixel106', 'pixel107', 'pixel108', 'pixel109', 'pixel110', 'pixel111', 'pixel112', 'pixel113', 'pixel114', 'pixel115', 'pixel116', 'pixel117', 'pixel118', 'pixel119', 'pixel120', 'pixel121', 'pixel122', 'pixel123', 'pixel124', 'pixel125', 'pixel126', 'pixel127', 'pixel128', 'pixel129', 'pixel130', 'pixel131', 'pixel132', 'pixel133', 'pixel134', 'pixel135', 'pixel136', 'pixel137', 'pixel138', 'pixel139', 'pixel140', 'pixel141', 'pixel142', 'pixel143', 'pixel144', 'pixel145', 'pixel146', 'pixel147', 'pixel148', 'pixel149', 'pixel150', 'pixel151', 'pixel152', 'pixel153', 'pixel154', 'pixel155', 'pixel156', 'pixel157', 'pixel158', 'pixel159', 'pixel160', 'pixel161', 'pixel162', 'pixel163', 'pixel164', 'pixel165', 'pixel166', 'pixel167', 'pixel168', 'pixel169', 'pixel170', 'pixel171', 'pixel172', 'pixel173', 'pixel174', 'pixel175', 'pixel176', 'pixel177', 'pixel178', 'pixel179', 'pixel180', 'pixel181', 'pixel182', 'pixel183', 'pixel184', 'pixel185', 'pixel186', 'pixel187', 'pixel188', 'pixel189', 'pixel190', 'pixel191', 'pixel192', 'pixel193', 'pixel194', 'pixel195', 'pixel196', 'pixel197', 'pixel198', 'pixel199', 'pixel200', 'pixel201', 'pixel202', 'pixel203', 'pixel204', 'pixel205', 'pixel206', 'pixel207', 'pixel208', 'pixel209', 'pixel210', 'pixel211', 'pixel212', 'pixel213', 'pixel214', 'pixel215', 'pixel216', 'pixel217', 'pixel218', 'pixel219', 'pixel220', 'pixel221', 'pixel222', 'pixel223', 'pixel224', 'pixel225', 'pixel226', 'pixel227', 'pixel228', 'pixel229', 'pixel230', 'pixel231', 'pixel232', 'pixel233', 'pixel234', 'pixel235', 'pixel236', 'pixel237', 'pixel238', 'pixel239', 'pixel240', 'pixel241', 'pixel242', 'pixel243', 'pixel244', 'pixel245', 'pixel246', 'pixel247', 'pixel248', 'pixel249', 'pixel250', 'pixel251', 'pixel252', 'pixel253', 'pixel254', 'pixel255', 'pixel256', 'pixel257', 'pixel258', 'pixel259', 'pixel260', 'pixel261', 'pixel262', 'pixel263', 'pixel264', 'pixel265', 'pixel266', 'pixel267', 'pixel268', 'pixel269', 'pixel270', 'pixel271', 'pixel272', 'pixel273', 'pixel274', 'pixel275', 'pixel276', 'pixel277', 'pixel278', 'pixel279', 'pixel280', 'pixel281', 'pixel282', 'pixel283', 'pixel284', 'pixel285', 'pixel286', 'pixel287', 'pixel288', 'pixel289', 'pixel290', 'pixel291', 'pixel292', 'pixel293', 'pixel294', 'pixel295', 'pixel296', 'pixel297', 'pixel298', 'pixel299', 'pixel300', 'pixel301', 'pixel302', 'pixel303', 'pixel304', 'pixel305', 'pixel306', 'pixel307', 'pixel308', 'pixel309', 'pixel310', 'pixel311', 'pixel312', 'pixel313', 'pixel314', 'pixel315', 'pixel316', 'pixel317', 'pixel318', 'pixel319', 'pixel320', 'pixel321', 'pixel322', 'pixel323', 'pixel324', 'pixel325', 'pixel326', 'pixel327', 'pixel328', 'pixel329', 'pixel330', 'pixel331', 'pixel332', 'pixel333', 'pixel334', 'pixel335', 'pixel336', 'pixel337', 'pixel338', 'pixel339', 'pixel340', 'pixel341', 'pixel342', 'pixel343', 'pixel344', 'pixel345', 'pixel346', 'pixel347', 'pixel348', 'pixel349', 'pixel350', 'pixel351', 'pixel352', 'pixel353', 'pixel354', 'pixel355', 'pixel356', 'pixel357', 'pixel358', 'pixel359', 'pixel360', 'pixel361', 'pixel362', 'pixel363', 'pixel364', 'pixel365', 'pixel366', 'pixel367', 'pixel368', 'pixel369', 'pixel370', 'pixel371', 'pixel372', 'pixel373', 'pixel374', 'pixel375', 'pixel376', 'pixel377', 'pixel378', 'pixel379', 'pixel380', 'pixel381', 'pixel382', 'pixel383', 'pixel384', 'pixel385', 'pixel386', 'pixel387', 'pixel388', 'pixel389', 'pixel390', 'pixel391', 'pixel392', 'pixel393', 'pixel394', 'pixel395', 'pixel396', 'pixel397', 'pixel398', 'pixel399', 'pixel400', 'pixel401', 'pixel402', 'pixel403', 'pixel404', 'pixel405', 'pixel406', 'pixel407', 'pixel408', 'pixel409', 'pixel410', 'pixel411', 'pixel412', 'pixel413', 'pixel414', 'pixel415', 'pixel416', 'pixel417', 'pixel418', 'pixel419', 'pixel420', 'pixel421', 'pixel422', 'pixel423', 'pixel424', 'pixel425', 'pixel426', 'pixel427', 'pixel428', 'pixel429', 'pixel430', 'pixel431', 'pixel432', 'pixel433', 'pixel434', 'pixel435', 'pixel436', 'pixel437', 'pixel438', 'pixel439', 'pixel440', 'pixel441', 'pixel442', 'pixel443', 'pixel444', 'pixel445', 'pixel446', 'pixel447', 'pixel448', 'pixel449', 'pixel450', 'pixel451', 'pixel452', 'pixel453', 'pixel454', 'pixel455', 'pixel456', 'pixel457', 'pixel458', 'pixel459', 'pixel460', 'pixel461', 'pixel462', 'pixel463', 'pixel464', 'pixel465', 'pixel466', 'pixel467', 'pixel468', 'pixel469', 'pixel470', 'pixel471', 'pixel472', 'pixel473', 'pixel474', 'pixel475', 'pixel476', 'pixel477', 'pixel478', 'pixel479', 'pixel480', 'pixel481', 'pixel482', 'pixel483', 'pixel484', 'pixel485', 'pixel486', 'pixel487', 'pixel488', 'pixel489', 'pixel490', 'pixel491', 'pixel492', 'pixel493', 'pixel494', 'pixel495', 'pixel496', 'pixel497', 'pixel498', 'pixel499', 'pixel500', 'pixel501', 'pixel502', 'pixel503', 'pixel504', 'pixel505', 'pixel506', 'pixel507', 'pixel508', 'pixel509', 'pixel510', 'pixel511', 'pixel512', 'pixel513', 'pixel514', 'pixel515', 'pixel516', 'pixel517', 'pixel518', 'pixel519', 'pixel520', 'pixel521', 'pixel522', 'pixel523', 'pixel524', 'pixel525', 'pixel526', 'pixel527', 'pixel528', 'pixel529', 'pixel530', 'pixel531', 'pixel532', 'pixel533', 'pixel534', 'pixel535', 'pixel536', 'pixel537', 'pixel538', 'pixel539', 'pixel540', 'pixel541', 'pixel542', 'pixel543', 'pixel544', 'pixel545', 'pixel546', 'pixel547', 'pixel548', 'pixel549', 'pixel550', 'pixel551', 'pixel552', 'pixel553', 'pixel554', 'pixel555', 'pixel556', 'pixel557', 'pixel558', 'pixel559', 'pixel560', 'pixel561', 'pixel562', 'pixel563', 'pixel564', 'pixel565', 'pixel566', 'pixel567', 'pixel568', 'pixel569', 'pixel570', 'pixel571', 'pixel572', 'pixel573', 'pixel574', 'pixel575', 'pixel576', 'pixel577', 'pixel578', 'pixel579', 'pixel580', 'pixel581', 'pixel582', 'pixel583', 'pixel584', 'pixel585', 'pixel586', 'pixel587', 'pixel588', 'pixel589', 'pixel590', 'pixel591', 'pixel592', 'pixel593', 'pixel594', 'pixel595', 'pixel596', 'pixel597', 'pixel598', 'pixel599', 'pixel600', 'pixel601', 'pixel602', 'pixel603', 'pixel604', 'pixel605', 'pixel606', 'pixel607', 'pixel608', 'pixel609', 'pixel610', 'pixel611', 'pixel612', 'pixel613', 'pixel614', 'pixel615', 'pixel616', 'pixel617', 'pixel618', 'pixel619', 'pixel620', 'pixel621', 'pixel622', 'pixel623', 'pixel624', 'pixel625', 'pixel626', 'pixel627', 'pixel628', 'pixel629', 'pixel630', 'pixel631', 'pixel632', 'pixel633', 'pixel634', 'pixel635', 'pixel636', 'pixel637', 'pixel638', 'pixel639', 'pixel640', 'pixel641', 'pixel642', 'pixel643', 'pixel644', 'pixel645', 'pixel646', 'pixel647', 'pixel648', 'pixel649', 'pixel650', 'pixel651', 'pixel652', 'pixel653', 'pixel654', 'pixel655', 'pixel656', 'pixel657', 'pixel658', 'pixel659', 'pixel660', 'pixel661', 'pixel662', 'pixel663', 'pixel664', 'pixel665', 'pixel666', 'pixel667', 'pixel668', 'pixel669', 'pixel670', 'pixel671', 'pixel672', 'pixel673', 'pixel674', 'pixel675', 'pixel676', 'pixel677', 'pixel678', 'pixel679', 'pixel680', 'pixel681', 'pixel682', 'pixel683', 'pixel684', 'pixel685', 'pixel686', 'pixel687', 'pixel688', 'pixel689', 'pixel690', 'pixel691', 'pixel692', 'pixel693', 'pixel694', 'pixel695', 'pixel696', 'pixel697', 'pixel698', 'pixel699', 'pixel700', 'pixel701', 'pixel702', 'pixel703', 'pixel704', 'pixel705', 'pixel706', 'pixel707', 'pixel708', 'pixel709', 'pixel710', 'pixel711', 'pixel712', 'pixel713', 'pixel714', 'pixel715', 'pixel716', 'pixel717', 'pixel718', 'pixel719', 'pixel720', 'pixel721', 'pixel722', 'pixel723', 'pixel724', 'pixel725', 'pixel726', 'pixel727', 'pixel728', 'pixel729', 'pixel730', 'pixel731', 'pixel732', 'pixel733', 'pixel734', 'pixel735', 'pixel736', 'pixel737', 'pixel738', 'pixel739', 'pixel740', 'pixel741', 'pixel742', 'pixel743', 'pixel744', 'pixel745', 'pixel746', 'pixel747', 'pixel748', 'pixel749', 'pixel750', 'pixel751', 'pixel752', 'pixel753', 'pixel754', 'pixel755', 'pixel756', 'pixel757', 'pixel758', 'pixel759', 'pixel760', 'pixel761', 'pixel762', 'pixel763', 'pixel764', 'pixel765', 'pixel766', 'pixel767', 'pixel768', 'pixel769', 'pixel770', 'pixel771', 'pixel772', 'pixel773', 'pixel774', 'pixel775', 'pixel776', 'pixel777', 'pixel778', 'pixel779', 'pixel780', 'pixel781', 'pixel782', 'pixel783', 'pixel784'], 'target_names': ['class'], 'DESCR': \"**Author**: Yann LeCun, Corinna Cortes, Christopher J.C. Burges  \\n**Source**: [MNIST Website](http://yann.lecun.com/exdb/mnist/) - Date unknown  \\n**Please cite**:  \\n\\nThe MNIST database of handwritten digits with 784 features, raw data available at: http://yann.lecun.com/exdb/mnist/. It can be split in a training set of the first 60,000 examples, and a test set of 10,000 examples  \\n\\nIt is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image. It is a good database for people who want to try learning techniques and pattern recognition methods on real-world data while spending minimal efforts on preprocessing and formatting. The original black and white (bilevel) images from NIST were size normalized to fit in a 20x20 pixel box while preserving their aspect ratio. The resulting images contain grey levels as a result of the anti-aliasing technique used by the normalization algorithm. the images were centered in a 28x28 image by computing the center of mass of the pixels, and translating the image so as to position this point at the center of the 28x28 field.  \\n\\nWith some classification methods (particularly template-based methods, such as SVM and K-nearest neighbors), the error rate improves when the digits are centered by bounding box rather than center of mass. If you do this kind of pre-processing, you should report it in your publications. The MNIST database was constructed from NIST's NIST originally designated SD-3 as their training set and SD-1 as their test set. However, SD-3 is much cleaner and easier to recognize than SD-1. The reason for this can be found on the fact that SD-3 was collected among Census Bureau employees, while SD-1 was collected among high-school students. Drawing sensible conclusions from learning experiments requires that the result be independent of the choice of training set and test among the complete set of samples. Therefore it was necessary to build a new database by mixing NIST's datasets.  \\n\\nThe MNIST training set is composed of 30,000 patterns from SD-3 and 30,000 patterns from SD-1. Our test set was composed of 5,000 patterns from SD-3 and 5,000 patterns from SD-1. The 60,000 pattern training set contained examples from approximately 250 writers. We made sure that the sets of writers of the training set and test set were disjoint. SD-1 contains 58,527 digit images written by 500 different writers. In contrast to SD-3, where blocks of data from each writer appeared in sequence, the data in SD-1 is scrambled. Writer identities for SD-1 is available and we used this information to unscramble the writers. We then split SD-1 in two: characters written by the first 250 writers went into our new training set. The remaining 250 writers were placed in our test set. Thus we had two sets with nearly 30,000 examples each. The new training set was completed with enough examples from SD-3, starting at pattern # 0, to make a full set of 60,000 training patterns. Similarly, the new test set was completed with SD-3 examples starting at pattern # 35,000 to make a full set with 60,000 test patterns. Only a subset of 10,000 test images (5,000 from SD-1 and 5,000 from SD-3) is available on this site. The full 60,000 sample training set is available.\\n\\nDownloaded from openml.org.\", 'details': {'id': '554', 'name': 'mnist_784', 'version': '1', 'description_version': '2', 'format': 'ARFF', 'creator': ['Yann LeCun', 'Corinna Cortes', 'Christopher J.C. Burges'], 'upload_date': '2014-09-29T03:28:38', 'language': 'English', 'licence': 'Public', 'url': 'https://api.openml.org/data/v1/download/52667/mnist_784.arff', 'parquet_url': 'https://openml1.win.tue.nl/datasets/0000/0554/dataset_554.pq', 'file_id': '52667', 'default_target_attribute': 'class', 'tag': ['AzurePilot', 'OpenML-CC18', 'OpenML100', 'study_1', 'study_123', 'study_41', 'study_99', 'vision'], 'visibility': 'public', 'minio_url': 'https://openml1.win.tue.nl/datasets/0000/0554/dataset_554.pq', 'status': 'active', 'processing_date': '2020-11-20 20:12:09', 'md5_checksum': '0298d579eb1b86163de7723944c7e495'}, 'url': 'https://www.openml.org/d/554'}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "mnist=fetch_openml(\"mnist_784\",version=1)\n",
        "print(mnist.keys())\n",
        "print(mnist)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-3Dq1GoSQVw"
      },
      "source": [
        "Ora bisogna convertire i dati in un formato che deve essere manipolato in maniera semplice, si creerà la variabile X che avrà le informazioni per quanto riguarda l'immagine, e la y è la variabile che si vuole predire"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aU-ZClf4SR8w",
        "outputId": "43fc9629-451f-44b5-960a-2afca2537304"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  pixel9  \\\n",
            "0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
            "1     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
            "2     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
            "3     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
            "4     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
            "\n",
            "   pixel10  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
            "0      0.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
            "1      0.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
            "2      0.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
            "3      0.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
            "4      0.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
            "\n",
            "   pixel781  pixel782  pixel783  pixel784  \n",
            "0       0.0       0.0       0.0       0.0  \n",
            "1       0.0       0.0       0.0       0.0  \n",
            "2       0.0       0.0       0.0       0.0  \n",
            "3       0.0       0.0       0.0       0.0  \n",
            "4       0.0       0.0       0.0       0.0  \n",
            "\n",
            "[5 rows x 784 columns]\n",
            "0    5\n",
            "1    0\n",
            "2    4\n",
            "3    1\n",
            "4    9\n",
            "Name: class, dtype: category\n",
            "Categories (10, object): ['0', '1', '2', '3', ..., '6', '7', '8', '9']\n"
          ]
        }
      ],
      "source": [
        "X,y=mnist[\"data\"],mnist[\"target\"]\n",
        "print(X.head())\n",
        "print(y.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXnwf50qU9ph"
      },
      "source": [
        "Bisogna convertire la target variable in un intero di 8 bit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "VGAyL7hsVCur"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "\n",
        "y=y.astype(np.uint8)\n",
        "classes=y.drop_duplicates().sort_values().tolist()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "# Converti il dataset in un DataFrame di Pandas\n",
        "mnist_df = pd.DataFrame(data=mnist.data, columns=mnist.feature_names)\n",
        "mnist_df['target'] = mnist.target\n",
        "\n",
        "# Utilizza pd.isna() per contare i valori nulli\n",
        "nan_mask = mnist_df.isna()\n",
        "nan_count = nan_mask.sum()\n",
        "\n",
        "print(nan_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gtbrlaSbKcM",
        "outputId": "955a4d00-d9b0-4767-e9a6-5d4c2edc7d64"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pixel1      0\n",
            "pixel2      0\n",
            "pixel3      0\n",
            "pixel4      0\n",
            "pixel5      0\n",
            "           ..\n",
            "pixel781    0\n",
            "pixel782    0\n",
            "pixel783    0\n",
            "pixel784    0\n",
            "target      0\n",
            "Length: 785, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LdgjDT8jVEuQ",
        "outputId": "72b373e9-0a40-4f0e-d3b8-77e1e3cb2f5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 70000 entries, 0 to 69999\n",
            "Columns: 784 entries, pixel1 to pixel784\n",
            "dtypes: float64(784)\n",
            "memory usage: 418.7 MB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(X.info())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "# Carica il dataset MNIST\n",
        "(x_train, y_train), (_, _) = mnist.load_data()\n",
        "\n",
        "# Calcola statistiche di base\n",
        "mean_pixel_value = np.mean(x_train)\n",
        "std_pixel_value = np.std(x_train)\n",
        "min_pixel_value = np.min(x_train)\n",
        "max_pixel_value = np.max(x_train)\n",
        "\n",
        "# Stampa delle statistiche\n",
        "print(f\"Media del valore dei pixel: {mean_pixel_value}\")\n",
        "print(f\"Deviazione standard del valore dei pixel: {std_pixel_value}\")\n",
        "print(f\"Valore minimo del pixel: {min_pixel_value}\")\n",
        "print(f\"Valore massimo del pixel: {max_pixel_value}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnVO3pW2n2B-",
        "outputId": "a3d21bd5-e90e-4cb1-d021-5261b11ff38c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "Media del valore dei pixel: 33.318421449829934\n",
            "Deviazione standard del valore dei pixel: 78.56748998339798\n",
            "Valore minimo del pixel: 0\n",
            "Valore massimo del pixel: 255\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-xQKWoxVY4w"
      },
      "source": [
        "Ora si divide il dataset in un testset e un trainingset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_vyZMwRVYl_",
        "outputId": "1c88094f-55b9-4b9d-d18e-e76bfda0ca4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number transactions X_train dataset:  (56000, 784)\n",
            "Number transactions y_train dataset:  (56000,)\n",
            "Number transactions X_test dataset:  (14000, 784)\n",
            "Number transactions y_test dataset:  (14000,)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Number transactions X_train dataset: \", X_train.shape)\n",
        "print(\"Number transactions y_train dataset: \", y_train.shape)\n",
        "print(\"Number transactions X_test dataset: \", X_test.shape)\n",
        "print(\"Number transactions y_test dataset: \", y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oduVER0C21NK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "MzHC4cNC1BU8",
        "outputId": "1d6d6abc-30f4-4c7c-b674-7e01707e1c31"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'module' object is not subscriptable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-d9604f3d6752>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmnist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"target\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Frequency'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'module' object is not subscriptable"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "pd.value_counts(mnist[\"target\"]).plot.bar()\n",
        "plt.xlabel('target')\n",
        "plt.ylabel('Frequency')\n",
        "mnist[\"target\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "jRVnrFeI1DKG"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "num_pipeline=Pipeline([\n",
        "    ('std_scaler',StandardScaler())\n",
        "])\n",
        "\n",
        "X_train_prepared=num_pipeline.fit_transform(X_train)\n",
        "X_test_prepared=num_pipeline.fit_transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Calcola alcune statistiche di sintesi utilizzando NumPy\n",
        "mean_values = np.mean(X_train_prepared, axis=0)\n",
        "std_dev_values = np.std(X_train_prepared, axis=0)\n",
        "min_values = np.min(X_train_prepared, axis=0)\n",
        "max_values = np.max(X_train_prepared, axis=0)\n",
        "\n",
        "# Stampa le statistiche\n",
        "print(\"Mean:\", mean_values)\n",
        "print(\"Standard Deviation:\", std_dev_values)\n",
        "print(\"Minimum:\", min_values)\n",
        "print(\"Maximum:\", max_values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVnZnW9kfA1v",
        "outputId": "6b1e2b91-0c56-4009-a04c-d9b80fac4c3f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean: [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            " -1.52259158e-18  0.00000000e+00 -1.52259158e-18 -1.52259158e-18\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  2.03012210e-18  1.26882631e-18  0.00000000e+00\n",
            "  6.02692499e-18  2.53765263e-18 -6.34413157e-19  4.44089210e-18\n",
            " -6.47101420e-18 -6.09036631e-18 -6.34413157e-18  1.09119063e-17\n",
            " -1.62409768e-17 -2.28388736e-18  3.55271368e-18 -8.24737104e-18\n",
            "  4.44089210e-18 -1.01506105e-18  3.80647894e-19 -1.96668079e-18\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00 -1.90323947e-19\n",
            " -2.03012210e-18 -3.04518315e-18 -1.26882631e-18  4.31400947e-18\n",
            "  2.51862023e-17  4.56777473e-18  9.76996262e-18 -4.12368552e-17\n",
            "  8.88178420e-18  5.07530526e-18 -2.00474558e-17 -1.12925542e-17\n",
            "  1.52259158e-17  4.56777473e-18 -3.60346673e-17  3.03249489e-17\n",
            "  1.86517468e-17 -3.26088363e-17 -1.02774931e-17 -5.07530526e-18\n",
            " -5.07530526e-19  2.53765263e-19  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  0.00000000e+00  1.26882631e-19 -1.26882631e-18\n",
            "  7.61295788e-19 -2.53765263e-19  1.57334463e-17  0.00000000e+00\n",
            "  1.67485073e-17 -1.97936905e-17  6.87703862e-17  1.75098031e-17\n",
            "  3.27357189e-17  2.32195215e-17 -2.08721929e-17 -1.52259158e-18\n",
            "  5.50670620e-17  2.60109394e-17  7.07370670e-17 -1.07850237e-17\n",
            "  2.29657563e-17  3.03249489e-17  1.01506105e-17  2.58840568e-17\n",
            " -1.11022302e-17 -1.26882631e-19 -3.80647894e-18  0.00000000e+00\n",
            "  0.00000000e+00  1.01506105e-18 -5.32907052e-18  2.79141789e-18\n",
            "  1.19269674e-17  2.18238126e-17 -2.71528831e-17  6.09036631e-18\n",
            "  3.23550710e-17  7.68908746e-17 -9.13554946e-18 -5.61455644e-17\n",
            "  8.13317667e-17  2.48689958e-17  8.85640767e-17 -5.07530526e-19\n",
            "  1.06581410e-17 -6.85166209e-18 -8.50113630e-18 -2.20775779e-17\n",
            "  6.19187241e-17  2.48689958e-17  5.88735410e-17 -4.94842262e-18\n",
            "  2.96905357e-17  6.50273486e-18 -2.03012210e-18 -7.35919262e-18\n",
            "  0.00000000e+00 -2.09356342e-18  5.45595315e-18  4.44089210e-18\n",
            "  2.13162821e-17 -2.10625168e-17 -3.16254959e-17  1.35764416e-17\n",
            "  3.93336157e-17 -1.87786294e-17 -7.61295788e-19  5.53208273e-17\n",
            "  4.18712684e-17 -5.06261699e-17 -5.79853625e-17 -5.73509494e-17\n",
            "  6.09036631e-18 -8.37425367e-18 -5.53208273e-17  9.64307999e-17\n",
            "  9.64307999e-18  8.04435883e-17  3.50513269e-17  4.51702168e-17\n",
            "  3.92067331e-17  2.03012210e-18 -6.47101420e-18  4.06024420e-18\n",
            "  0.00000000e+00  6.34413157e-19  4.82153999e-18 -1.52259158e-18\n",
            " -9.13554946e-18 -5.07530526e-17  1.44646200e-17  7.84134662e-17\n",
            "  7.81597009e-17  1.90323947e-17 -2.36001694e-17  1.06581410e-17\n",
            "  6.09036631e-17 -4.16175031e-17 -3.52733715e-17  9.00866683e-17\n",
            " -4.64390431e-17 -5.58283578e-18  1.95399252e-17 -4.47895689e-17\n",
            "  5.43057662e-17  7.61295788e-18 -5.17681136e-17  5.55111512e-17\n",
            "  3.97142636e-17  2.80252012e-17  6.59789683e-18 -5.07530526e-18\n",
            "  0.00000000e+00  7.61295788e-19 -2.53765263e-18 -3.04518315e-18\n",
            " -3.36873386e-17 -6.34413157e-18 -5.22756441e-17 -1.62409768e-17\n",
            "  6.95316820e-17 -6.47101420e-17 -7.25768652e-17 -9.59232693e-17\n",
            "  7.61295788e-19 -7.86672315e-18 -6.64864988e-17 -3.24819536e-17\n",
            " -6.00154846e-17 -3.60346673e-17  1.67485073e-17 -8.37425367e-18\n",
            "  4.51702168e-17  2.42345826e-17  1.34495589e-17  3.43217518e-17\n",
            " -2.61378221e-17  2.06184276e-17 -3.32432494e-17 -2.03012210e-18\n",
            " -2.34732868e-18  6.97854473e-18  2.30926389e-17 -1.09119063e-17\n",
            "  5.37982357e-17  1.01506105e-18  2.89292400e-17  1.87786294e-17\n",
            " -9.79533914e-17  3.80647894e-18  4.41551557e-17 -5.44326489e-17\n",
            "  2.68356765e-17 -4.50433341e-17 -5.07530526e-19  7.18155694e-17\n",
            " -1.00998575e-16  5.22756441e-17  4.65659257e-17  2.53765263e-18\n",
            " -6.39488462e-17 -4.69465736e-18  1.92861600e-17 -1.22822387e-16\n",
            " -5.07530526e-18  2.84217094e-17 -1.56065637e-17  3.04518315e-18\n",
            " -7.61295788e-19 -1.04678171e-17  3.86992026e-18 -3.29894842e-18\n",
            " -1.72560379e-17 -3.85723199e-17 -1.47183852e-17 -2.84217094e-17\n",
            " -2.53765263e-19 -5.53208273e-17  4.94842262e-18  4.98648741e-17\n",
            "  5.46864141e-17 -8.44403912e-17 -5.95079541e-17  3.36238973e-18\n",
            " -4.03486768e-17  9.40200299e-17 -5.58600785e-17 -3.50196063e-17\n",
            "  6.49639073e-17  2.80410615e-17 -5.37982357e-17 -6.95316820e-17\n",
            " -4.66928083e-17  1.07215824e-17 -1.85248642e-17 -4.06024420e-18\n",
            " -7.61295788e-19  1.30689110e-17  8.88178420e-19 -1.57334463e-17\n",
            "  1.78904510e-17  2.38539347e-17  1.77635684e-17 -9.23705556e-17\n",
            "  1.52259158e-18 -3.09593621e-17  7.08005083e-17 -3.78110242e-17\n",
            "  7.04833017e-17  8.75490157e-17  4.56777473e-18 -5.50670620e-17\n",
            " -3.78110242e-17 -2.66453526e-18  3.70497284e-17 -5.78584799e-17\n",
            " -6.14111936e-17  3.93336157e-17  2.72797657e-17 -1.77635684e-18\n",
            "  4.94842262e-18 -3.03249489e-17  0.00000000e+00  4.31400947e-18\n",
            " -5.70971841e-19 -1.11656716e-17  1.94130426e-17  2.85485921e-17\n",
            " -4.31400947e-17  3.32432494e-17 -3.80647894e-18  2.63915873e-17\n",
            " -1.06581410e-17  4.31400947e-18  5.04992873e-17  1.72560379e-17\n",
            "  1.11656716e-16 -2.32195215e-17  1.75098031e-17  2.03012210e-18\n",
            " -6.55983204e-17 -8.72318091e-17  4.39013905e-17  6.69940294e-17\n",
            " -1.95399252e-17 -5.20218789e-17 -2.80410615e-17 -7.51145178e-17\n",
            " -4.06024420e-18 -2.66453526e-18  1.78904510e-17  5.07530526e-19\n",
            "  2.91830052e-18  5.83660104e-18  1.37667655e-17  1.89689534e-17\n",
            " -2.46152305e-17 -2.48689958e-17  4.36476252e-17 -4.56777473e-18\n",
            " -4.33938599e-17 -1.07596471e-16 -5.48132968e-17 -6.83897383e-17\n",
            "  4.39013905e-17  4.04755594e-17 -2.43614652e-17  2.91830052e-17\n",
            "  7.38456915e-17  8.55188936e-17 -1.72560379e-17 -2.58840568e-17\n",
            "  7.10542736e-18 -2.81679442e-17 -2.72797657e-17 -1.92861600e-17\n",
            "  2.94367705e-17  1.71291552e-17  3.17206578e-18 -2.28388736e-18\n",
            "  6.34413157e-19  2.91830052e-18  3.55271368e-18  1.39570895e-18\n",
            " -2.03012210e-18 -5.32907052e-18  5.68434189e-17 -7.34650436e-17\n",
            "  2.53765263e-17 -5.78584799e-17  9.18630251e-17  7.66371094e-17\n",
            " -4.28863294e-17  5.27831747e-17  3.78110242e-17 -5.22756441e-17\n",
            "  2.94367705e-17  4.04755594e-17 -1.06581410e-16 -3.04518315e-17\n",
            " -5.32907052e-18  6.22993720e-17  1.70022726e-17 -2.10625168e-17\n",
            " -3.67959631e-17 -1.67485073e-17  3.80647894e-18  2.53765263e-19\n",
            " -1.20538500e-18  3.29894842e-18  1.77635684e-18  1.43377373e-17\n",
            "  4.56777473e-18  4.45358036e-17 -1.03409345e-17  2.23313431e-17\n",
            "  3.75572589e-17  9.74458609e-17 -4.92304610e-17  7.81597009e-17\n",
            "  2.36001694e-17  8.04435883e-17  2.68991179e-17  1.25804129e-16\n",
            " -4.13002965e-17  8.67877199e-17  1.92861600e-17  2.38539347e-17\n",
            "  5.07530526e-18 -9.13554946e-18 -5.09433765e-17  8.88178420e-18\n",
            "  4.41551557e-17 -7.61295788e-19  1.83979816e-18 -5.83660104e-18\n",
            " -7.61295788e-19 -5.07530526e-19 -2.28388736e-18 -1.42108547e-17\n",
            "  3.35604560e-17 -3.36238973e-17  3.14668926e-17 -1.13559955e-17\n",
            "  3.71766110e-17 -3.03883902e-17 -5.53208273e-17  5.04992873e-17\n",
            " -5.64627710e-17 -4.87229305e-17 -1.31069758e-16 -9.92222177e-17\n",
            "  4.53605407e-17  2.28388736e-17  6.95316820e-17 -8.12048841e-18\n",
            " -5.32907052e-17 -2.79141789e-17  1.85248642e-17 -3.70497284e-17\n",
            "  1.37033242e-17  3.99680289e-17 -3.80647894e-19  2.79141789e-18\n",
            " -5.70971841e-19  1.01506105e-18  1.07850237e-17 -1.47183852e-17\n",
            "  2.08087515e-17 -1.30689110e-17 -1.29420284e-17  1.85248642e-17\n",
            " -4.26325641e-17  3.88260852e-17 -9.74458609e-17  3.10862447e-17\n",
            "  6.54714378e-17  4.06024420e-17 -3.98411463e-17 -3.01980663e-17\n",
            "  5.70971841e-17  7.61295788e-17 -2.03012210e-17 -6.09036631e-18\n",
            " -6.75015599e-17 -5.22756441e-17  3.93336157e-18  8.86909593e-17\n",
            " -4.44089210e-17 -2.68991179e-17 -1.26882631e-18 -3.80647894e-19\n",
            "  0.00000000e+00 -2.03012210e-18  1.07850237e-17 -1.41474134e-17\n",
            "  6.90241515e-17  3.00077423e-17 -4.28228881e-17  4.87229305e-17\n",
            " -1.12671777e-16  6.85166209e-17  4.64390431e-17  1.44646200e-17\n",
            " -4.51702168e-17  7.15618041e-17  4.46626862e-17  9.04673162e-17\n",
            " -3.93336157e-17  1.62409768e-17  1.95399252e-17 -3.01980663e-17\n",
            " -7.35919262e-18 -6.92779167e-17  1.14194368e-17  4.89766957e-17\n",
            "  1.29420284e-17  1.67485073e-17  9.38931472e-18  2.79141789e-18\n",
            "  5.45595315e-18 -5.20218789e-18  5.83660104e-18 -1.97936905e-17\n",
            " -1.42742960e-17  3.79696274e-17 -5.93810715e-17 -6.78822078e-17\n",
            "  8.67877199e-17  2.72797657e-17 -3.62884326e-17  5.81122452e-17\n",
            "  9.13554946e-17  4.41551557e-17  4.41551557e-17  3.78110242e-17\n",
            " -7.56220483e-17 -6.95316820e-17 -2.11259581e-17 -4.54239820e-17\n",
            "  9.76996262e-18 -1.34495589e-17 -1.47183852e-17 -3.47658410e-17\n",
            " -1.06581410e-17 -7.86672315e-18  7.86672315e-18  1.52259158e-18\n",
            " -3.04518315e-18  1.45915026e-18 -1.47183852e-17  1.26882631e-18\n",
            " -2.75335310e-17  2.66453526e-18 -1.05851835e-16 -2.86754747e-17\n",
            "  4.99917568e-17  5.67165362e-17  1.10134124e-16 -8.52651283e-17\n",
            " -6.95316820e-17  3.90798505e-17  3.19744231e-17 -2.28388736e-17\n",
            " -3.46389584e-17 -2.27754323e-17 -4.74541041e-17  5.19584376e-17\n",
            " -4.61852778e-17  2.48689958e-17 -1.16732021e-17 -1.75098031e-17\n",
            "  2.28388736e-18 -2.58206155e-17 -9.89684525e-18  5.45595315e-18\n",
            "  0.00000000e+00  2.53765263e-19  5.45595315e-18  1.72560379e-17\n",
            "  3.65421978e-17  9.28780862e-17 -3.78744655e-17  5.32272639e-17\n",
            " -3.23550710e-17 -1.22187974e-16  4.44089210e-17 -1.85248642e-17\n",
            "  4.03486768e-17 -9.38931472e-18  2.36001694e-17 -5.63358883e-17\n",
            "  7.05467431e-17 -4.42820384e-17  2.04281037e-17  1.82710989e-17\n",
            " -1.82710989e-17 -1.77635684e-17 -1.86517468e-17 -1.26882631e-18\n",
            " -2.13797234e-17  1.59872116e-17  2.03012210e-18 -3.04518315e-18\n",
            " -2.09356342e-18  6.59789683e-18  8.62801893e-18  8.75490157e-18\n",
            " -4.89132544e-17  3.21013057e-17 -8.81834288e-17  3.48927236e-18\n",
            "  4.68196910e-17  5.07530526e-19 -7.33381609e-17 -6.39488462e-17\n",
            " -8.12048841e-17 -4.10465313e-17 -2.27754323e-17 -3.93336157e-18\n",
            " -1.43377373e-17  6.54714378e-17  5.02455220e-17 -4.66928083e-17\n",
            "  5.48132968e-17 -7.35919262e-17 -5.58283578e-18  6.14111936e-17\n",
            " -4.31400947e-18 -1.87151881e-17 -7.61295788e-19 -1.83979816e-18\n",
            " -6.97854473e-19 -1.77635684e-18  1.00237279e-17 -3.09593621e-17\n",
            " -2.28388736e-18  5.55111512e-17 -5.70971841e-19 -1.35130002e-17\n",
            "  9.05941988e-17 -6.90241515e-17 -1.57334463e-17  6.57252031e-17\n",
            "  5.13874657e-18  4.97379915e-17  9.50350909e-17  4.32669773e-17\n",
            "  6.80090904e-17  1.42108547e-16  1.95399252e-17 -3.04518315e-18\n",
            " -3.55271368e-17  6.07767804e-17 -6.09036631e-18  2.61378221e-17\n",
            "  2.84217094e-17  9.64307999e-18  6.72477946e-18 -8.24737104e-19\n",
            "  0.00000000e+00 -2.09356342e-18 -7.86672315e-18 -2.41077000e-18\n",
            " -8.81834288e-18 -2.77872963e-17 -1.03092138e-16 -8.12048841e-18\n",
            "  4.92304610e-17 -1.16732021e-17 -2.89292400e-17 -3.89529678e-17\n",
            "  1.15463195e-17 -3.42583105e-17 -1.75732444e-17  8.88178420e-18\n",
            "  2.91830052e-17  4.06024420e-17  3.85723199e-17  3.45120757e-17\n",
            "  2.28388736e-18 -5.88735410e-17 -9.89684525e-18 -1.31957937e-17\n",
            "  2.79141789e-18  5.07530526e-19 -7.61295788e-19  0.00000000e+00\n",
            "  0.00000000e+00  0.00000000e+00  1.90323947e-18  5.07530526e-19\n",
            " -2.02377797e-17  2.86754747e-17  1.06581410e-17  3.37507799e-17\n",
            " -5.37982357e-17  1.91592773e-17 -2.27119910e-17  5.03724047e-17\n",
            "  2.03012210e-18  6.44563767e-17  4.41551557e-17  9.99835135e-17\n",
            "  3.24819536e-17 -7.30843957e-17 -6.92779167e-17  3.80647894e-18\n",
            " -1.16732021e-17 -4.45358036e-17 -6.85166209e-18 -1.21807326e-17\n",
            " -9.89684525e-18 -1.52259158e-18  1.64947421e-18  0.00000000e+00\n",
            "  0.00000000e+00  0.00000000e+00  3.04518315e-18 -4.56777473e-18\n",
            " -5.32907052e-18  2.13162821e-17 -1.49721505e-17 -3.14668926e-17\n",
            " -2.10625168e-17  3.74303763e-17 -3.86357613e-17 -6.72477946e-18\n",
            " -2.25851084e-17 -4.96111089e-17  3.24819536e-17 -4.00949115e-17\n",
            " -2.03012210e-18 -6.80090904e-17  8.12048841e-18 -1.44646200e-17\n",
            "  4.19981510e-17 -5.32907052e-18 -1.47183852e-17 -2.03012210e-18\n",
            " -1.77635684e-18 -6.34413157e-19  1.64947421e-18  0.00000000e+00\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            " -4.31400947e-18  1.19269674e-17  2.69625592e-18  1.72560379e-17\n",
            " -2.53765263e-17  1.21807326e-17 -1.77635684e-17  3.73669349e-17\n",
            "  2.49958784e-17  1.39570895e-17 -4.87229305e-17 -1.14194368e-17\n",
            "  1.06581410e-17  3.34970147e-17  2.53765263e-18 -2.08087515e-17\n",
            "  6.34413157e-18  4.31400947e-18  1.77635684e-18  1.39570895e-18\n",
            " -3.55271368e-18 -2.34732868e-18  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            " -1.26882631e-19 -4.88498131e-18  1.26882631e-18 -2.41077000e-18\n",
            "  7.61295788e-19  3.42583105e-18  1.37033242e-17 -1.59872116e-17\n",
            " -3.29894842e-18  1.64947421e-18 -3.85723199e-17  1.30689110e-17\n",
            " -1.09119063e-17 -1.61140942e-17  5.07530526e-19 -5.96348368e-18\n",
            "  7.61295788e-19  1.26882631e-18 -3.17206578e-19 -5.70971841e-19\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "Standard Deviation: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
            " 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
            "Minimum: [ 0.          0.          0.          0.          0.          0.\n",
            "  0.          0.          0.          0.          0.          0.\n",
            " -0.00457315 -0.00595681 -0.00422581 -0.00422581  0.          0.\n",
            "  0.          0.          0.          0.          0.          0.\n",
            "  0.          0.          0.          0.          0.          0.\n",
            "  0.          0.         -0.00422581 -0.00644617 -0.00859209 -0.01091681\n",
            " -0.01355956 -0.01941039 -0.02448325 -0.02895702 -0.0301599  -0.03233274\n",
            " -0.0332658  -0.02905717 -0.02870756 -0.02701646 -0.02273783 -0.01762933\n",
            " -0.01644529 -0.01059506 -0.00764366 -0.00422581  0.          0.\n",
            "  0.          0.          0.          0.          0.         -0.00422581\n",
            " -0.00809245 -0.01071301 -0.01764173 -0.02844364 -0.03769862 -0.0536141\n",
            " -0.0693414  -0.0867893  -0.10304217 -0.1183097  -0.13060009 -0.13894392\n",
            " -0.1391637  -0.13120043 -0.11902825 -0.1002263  -0.07849209 -0.05709612\n",
            " -0.03858854 -0.02201752 -0.01146268 -0.00584382  0.          0.\n",
            "  0.          0.         -0.0051586  -0.00664566 -0.01342091 -0.02057424\n",
            " -0.03484885 -0.0558772  -0.08130872 -0.11195223 -0.14189451 -0.17155214\n",
            " -0.19973934 -0.22784236 -0.2495819  -0.26103048 -0.26141445 -0.24552206\n",
            " -0.22044604 -0.18578361 -0.14672802 -0.10763816 -0.07761952 -0.04828139\n",
            " -0.03069548 -0.01526469 -0.0067128   0.          0.         -0.00422581\n",
            " -0.00707467 -0.01436845 -0.02469672 -0.0472425  -0.07748818 -0.11617419\n",
            " -0.16222754 -0.21528114 -0.27058906 -0.33003081 -0.39463737 -0.45556898\n",
            " -0.50263435 -0.52492217 -0.5172186  -0.47981528 -0.4215292  -0.35555903\n",
            " -0.28346803 -0.21618581 -0.15822394 -0.10849931 -0.07036805 -0.03840138\n",
            " -0.01577939 -0.00597304  0.         -0.00422581 -0.01227603 -0.02180564\n",
            " -0.05320828 -0.09102768 -0.13964711 -0.19684558 -0.26489694 -0.34369768\n",
            " -0.42754166 -0.52160448 -0.62200362 -0.72173932 -0.79791529 -0.83777286\n",
            " -0.82512534 -0.76279925 -0.6669955  -0.55708874 -0.44853621 -0.34719397\n",
            " -0.25997425 -0.18908659 -0.13005766 -0.07429647 -0.03358506 -0.00742814\n",
            "  0.         -0.00576566 -0.01473744 -0.03725441 -0.08084246 -0.13393147\n",
            " -0.19940663 -0.27609371 -0.36600698 -0.4677341  -0.57998211 -0.70548464\n",
            " -0.83547596 -0.96236034 -1.06123161 -1.10826105 -1.08503183 -0.99942617\n",
            " -0.87567188 -0.72663346 -0.58085675 -0.45148843 -0.33728386 -0.24618275\n",
            " -0.17194552 -0.10364768 -0.04842086 -0.01424383  0.         -0.01116361\n",
            " -0.0257345  -0.06041134 -0.11328889 -0.17805077 -0.25706573 -0.35091194\n",
            " -0.46136654 -0.5875316  -0.72957236 -0.88226247 -1.01986627 -1.13569313\n",
            " -1.20229632 -1.23026693 -1.21160973 -1.14567891 -1.02467203 -0.86534944\n",
            " -0.6906222  -0.53182058 -0.39524471 -0.28430484 -0.19567071 -0.120829\n",
            " -0.05559241 -0.01430554 -0.00422581 -0.01718732 -0.04273877 -0.08545462\n",
            " -0.13925994 -0.20933871 -0.2969497  -0.40509648 -0.53472155 -0.68634379\n",
            " -0.85067076 -0.98961739 -1.07645064 -1.10498644 -1.10193998 -1.10322635\n",
            " -1.10927302 -1.10304319 -1.04836731 -0.91600255 -0.73885695 -0.56844144\n",
            " -0.42047979 -0.29475833 -0.19755498 -0.12043355 -0.05552699 -0.0138984\n",
            " -0.00726127 -0.02302188 -0.05249389 -0.09305928 -0.14921568 -0.22402498\n",
            " -0.3199381  -0.44034459 -0.58687827 -0.75750706 -0.91214552 -0.99812756\n",
            " -0.99305348 -0.94418153 -0.90473702 -0.91300382 -0.95572934 -1.00849665\n",
            " -1.00334716 -0.90208565 -0.73429646 -0.56466472 -0.41731583 -0.28664562\n",
            " -0.1814847  -0.10397219 -0.04801571 -0.0145914  -0.00787456 -0.02470221\n",
            " -0.05393163 -0.09250797 -0.14512654 -0.22396606 -0.32999529 -0.46243835\n",
            " -0.62491881 -0.79516747 -0.91816693 -0.93627275 -0.86557339 -0.79222609\n",
            " -0.77062929 -0.80373127 -0.87649499 -0.95741886 -0.96668801 -0.86315549\n",
            " -0.69947828 -0.53503091 -0.39530554 -0.26980442 -0.16039283 -0.0805479\n",
            " -0.03864328 -0.01255092 -0.00794827 -0.02185603 -0.04771139 -0.08137116\n",
            " -0.13455723 -0.22269306 -0.33710504 -0.48493214 -0.65662209 -0.82048826\n",
            " -0.90582616 -0.87568232 -0.78162021 -0.7308164  -0.73969054 -0.80360275\n",
            " -0.9063927  -0.98256389 -0.95772339 -0.82437418 -0.65478778 -0.49861738\n",
            " -0.36936603 -0.25764835 -0.15061879 -0.06131987 -0.02797427 -0.00926012\n",
            " -0.00549053 -0.01689208 -0.0368687  -0.06824691 -0.12604354 -0.22450266\n",
            " -0.35222251 -0.51073501 -0.68667494 -0.83538504 -0.89318896 -0.84271736\n",
            " -0.76529388 -0.76899138 -0.82136637 -0.92077052 -1.03470413 -1.06209744\n",
            " -0.96717265 -0.79322721 -0.61656034 -0.47048057 -0.35606005 -0.25574956\n",
            " -0.15401155 -0.0535165  -0.02152107 -0.00968983 -0.00422581 -0.01162487\n",
            " -0.02578724 -0.0563554  -0.1234243  -0.23774124 -0.37356206 -0.5354163\n",
            " -0.70660945 -0.84072826 -0.88141792 -0.84210659 -0.81622606 -0.89215507\n",
            " -0.9820665  -1.11614761 -1.18563089 -1.13076332 -0.97620392 -0.77530439\n",
            " -0.5950594  -0.46299044 -0.35796479 -0.2646742  -0.16473593 -0.06022012\n",
            " -0.02360614 -0.00722941 -0.00422581 -0.00747013 -0.01771952 -0.05020185\n",
            " -0.12797248 -0.25683222 -0.39449935 -0.55153471 -0.70921873 -0.82726369\n",
            " -0.86821162 -0.86145573 -0.90534099 -1.03664377 -1.15135247 -1.28024699\n",
            " -1.25316147 -1.14044792 -0.9640012  -0.76328572 -0.59788334 -0.4749622\n",
            " -0.36981595 -0.27444732 -0.17402263 -0.06944948 -0.02388467 -0.00723007\n",
            " -0.00493771 -0.00433647 -0.01918769 -0.05279373 -0.13987961 -0.27605759\n",
            " -0.40995187 -0.55328369 -0.69295268 -0.7936946  -0.84190159 -0.87086127\n",
            " -0.96163273 -1.098758   -1.21005799 -1.27945554 -1.18781049 -1.08016765\n",
            " -0.92519974 -0.75333226 -0.61186631 -0.49006571 -0.382479   -0.27976014\n",
            " -0.17615765 -0.07647721 -0.0270449  -0.00923391 -0.00422581 -0.00551352\n",
            " -0.02280099 -0.06105024 -0.15702175 -0.29504278 -0.41872596 -0.54434986\n",
            " -0.65957435 -0.74229883 -0.78976402 -0.8344115  -0.92095309 -1.02827124\n",
            " -1.12509091 -1.14914263 -1.08176952 -1.00374379 -0.88328854 -0.74803188\n",
            " -0.61993331 -0.49649396 -0.38214991 -0.27463835 -0.17380948 -0.0819752\n",
            " -0.03150529 -0.00927617  0.         -0.00914269 -0.02690461 -0.07465221\n",
            " -0.17742606 -0.31186936 -0.42598321 -0.53290194 -0.62191429 -0.68540938\n",
            " -0.72615348 -0.76659987 -0.82593877 -0.91868038 -1.00458425 -1.03348887\n",
            " -1.01333509 -0.95928903 -0.86244526 -0.74724305 -0.61880976 -0.4888029\n",
            " -0.37064694 -0.26169977 -0.16689226 -0.08618707 -0.03312654 -0.01142974\n",
            " -0.00611326 -0.00720016 -0.03424375 -0.09171269 -0.19838314 -0.32710349\n",
            " -0.43775401 -0.53387627 -0.60783939 -0.66197168 -0.70032885 -0.73302848\n",
            " -0.78165227 -0.86998308 -0.95737874 -1.01150305 -1.01374362 -0.95964038\n",
            " -0.86520322 -0.74044927 -0.60071695 -0.46716975 -0.35033643 -0.24532038\n",
            " -0.15572554 -0.08451766 -0.0311098  -0.01001263 -0.00422581 -0.00953048\n",
            " -0.0393185  -0.1042121  -0.20963319 -0.33670102 -0.45146224 -0.55276307\n",
            " -0.63454231 -0.69700245 -0.7438561  -0.77608817 -0.83010029 -0.91855601\n",
            " -1.00915209 -1.06206525 -1.05404916 -0.97108711 -0.85325079 -0.70806371\n",
            " -0.56031608 -0.42981726 -0.31728519 -0.21961623 -0.14026098 -0.07775961\n",
            " -0.02974065 -0.00757435  0.         -0.00946772 -0.04352885 -0.1094586\n",
            " -0.20582029 -0.32853197 -0.45427824 -0.56992567 -0.67468404 -0.76394646\n",
            " -0.83422944 -0.89183775 -0.96242636 -1.05288171 -1.12516317 -1.13285719\n",
            " -1.06880774 -0.9445845  -0.79391248 -0.63255824 -0.49155841 -0.36973652\n",
            " -0.26917517 -0.18607573 -0.12104441 -0.06635471 -0.02589018 -0.00597596\n",
            " -0.00422581 -0.00871236 -0.04025268 -0.09898178 -0.18543316 -0.29746097\n",
            " -0.42579885 -0.5548601  -0.6823117  -0.80426967 -0.91378015 -1.01407699\n",
            " -1.10860036 -1.18431139 -1.19904892 -1.13244879 -1.00181677 -0.83764423\n",
            " -0.67206407 -0.52516064 -0.39999498 -0.29570667 -0.21120335 -0.14768251\n",
            " -0.09595306 -0.04970732 -0.01966551 -0.00422581 -0.00422581 -0.00582329\n",
            " -0.0327038  -0.0775437  -0.14543293 -0.24048223 -0.35787844 -0.48529023\n",
            " -0.62201481 -0.75843358 -0.89126209 -1.00519744 -1.09148008 -1.12068449\n",
            " -1.08054649 -0.96994524 -0.82308338 -0.66875335 -0.52690299 -0.40268133\n",
            " -0.30222418 -0.21891991 -0.1558962  -0.10754585 -0.06874871 -0.0368558\n",
            " -0.01280046 -0.00422581  0.         -0.00422581 -0.02165407 -0.05022634\n",
            " -0.09858525 -0.16617427 -0.2585297  -0.36751015 -0.48900538 -0.61508849\n",
            " -0.73980271 -0.84375856 -0.90274294 -0.90076503 -0.84370785 -0.74056074\n",
            " -0.61790402 -0.49556048 -0.38228841 -0.28912375 -0.21139454 -0.14899298\n",
            " -0.10587282 -0.07067244 -0.04260365 -0.02044811 -0.00912273  0.\n",
            "  0.          0.         -0.00961316 -0.02734123 -0.05668275 -0.0943378\n",
            " -0.15265418 -0.22290114 -0.30232925 -0.38581669 -0.46780513 -0.53004106\n",
            " -0.56475409 -0.56233119 -0.53045811 -0.47398191 -0.40209133 -0.32776485\n",
            " -0.25663849 -0.19413001 -0.14300788 -0.0976774  -0.06761741 -0.04319441\n",
            " -0.02365701 -0.00946774 -0.0049197   0.          0.          0.\n",
            " -0.00689822 -0.01088033 -0.02717976 -0.0513168  -0.08578878 -0.12751383\n",
            " -0.17475396 -0.22183853 -0.2641895  -0.29254759 -0.30586219 -0.30512455\n",
            " -0.29075078 -0.26582041 -0.23566952 -0.20079391 -0.16202124 -0.12539125\n",
            " -0.09244956 -0.06301158 -0.04464582 -0.02714348 -0.01559449 -0.00593185\n",
            " -0.00422581  0.          0.          0.          0.          0.\n",
            " -0.0132041  -0.03015362 -0.05352382 -0.07943515 -0.10771737 -0.13252862\n",
            " -0.15461875 -0.17322835 -0.18131522 -0.1801191  -0.17077671 -0.15392196\n",
            " -0.13561243 -0.1157606  -0.09136667 -0.07132816 -0.05219341 -0.03490894\n",
            " -0.02102765 -0.01217684 -0.00475803 -0.00422581  0.          0.\n",
            "  0.          0.          0.          0.         -0.00476119 -0.0078707\n",
            " -0.01477243 -0.02162838 -0.02732851 -0.03141552 -0.04197198 -0.04659841\n",
            " -0.05184094 -0.05448585 -0.05866402 -0.05582409 -0.0512873  -0.04266059\n",
            " -0.03266832 -0.02334733 -0.01542342 -0.00938753 -0.00853673 -0.00422581\n",
            "  0.          0.          0.          0.        ]\n",
            "Maximum: [  0.           0.           0.           0.           0.\n",
            "   0.           0.           0.           0.           0.\n",
            "   0.           0.         235.7666323  180.26996535 236.64107843\n",
            " 236.64107843   0.           0.           0.           0.\n",
            "   0.           0.           0.           0.           0.\n",
            "   0.           0.           0.           0.           0.\n",
            "   0.           0.         236.64107843 182.42706377 172.30267777\n",
            " 123.32558619  96.85796112  75.35417608  52.63717944  48.10913091\n",
            "  43.65413074  43.17481043  39.88569155  45.27462657  50.84164363\n",
            "  47.18814027  60.47590754  72.82577888  75.16200471 133.29109839\n",
            " 144.36854887 236.64107843   0.           0.           0.\n",
            "   0.           0.           0.           0.         236.64107843\n",
            " 160.64210533 192.93108194  84.81533991  51.8524021   35.25609628\n",
            "  25.56661486  19.17119975  15.66861028  12.8846643   11.13809451\n",
            "  10.02712973   9.52206072   9.41642949   9.87650326  10.94947338\n",
            "  12.73881046  16.59487438  22.68325722  34.67942336  68.91248037\n",
            " 135.74642858 215.84245552   0.           0.           0.\n",
            "   0.         228.91993746 196.78843853 131.89110976  80.62729893\n",
            "  43.32882699  26.11937662  17.10065794  11.84399713   9.10774406\n",
            "   7.45047299   6.39443641   5.59277089   5.07657448   4.78348051\n",
            "   4.85284234   5.14290416   5.75196724   6.82551143   8.85491382\n",
            "  12.0083679   17.91161542  28.71869767  48.51099273 130.29647866\n",
            " 185.11249978   0.           0.         236.64107843 217.74146363\n",
            " 111.17127826  67.28438336  33.30205243  19.87798954  12.16037835\n",
            "   8.39584101   6.15350839   4.7713839    3.87537627   3.24882388\n",
            "   2.79881751   2.52639001   2.41911      2.46164053   2.66467771\n",
            "   3.03950863   3.61645902   4.59187407   6.17591091   8.72286503\n",
            "  13.00020448  21.00816256  46.167509    95.6709088  172.7225954\n",
            "   0.         236.64107843 106.00799176  87.27411413  32.6959919\n",
            "  15.77233015   9.85945399   6.76315154   4.91001088   3.72772886\n",
            "   2.96536328   2.42912627   2.03209577   1.74333353   1.57435407\n",
            "   1.5099273    1.53911737   1.6641649    1.91103559   2.28857421\n",
            "   2.86772702   3.7766477    5.12513086   7.17963236  11.14415393\n",
            "  23.14436752  53.54043274 193.42137384   0.         205.46147741\n",
            " 123.69138983  41.02426472  17.66379087  10.08591105   6.61786494\n",
            "   4.64366781   3.45760803   2.68509485   2.1691762    1.79842387\n",
            "   1.52558777   1.33147777   1.21181523   1.16039371   1.18486068\n",
            "   1.2734877    1.44418367   1.73162025   2.15823377   2.82197251\n",
            "   3.80169119   5.36931942   8.02889888  14.16158111  32.74864158\n",
            " 105.44049279   0.         128.96215185  64.23176137  25.10877687\n",
            "  12.24427171   7.44976633   5.04786197   3.63547707   2.75046956\n",
            "   2.16437193   1.76948034   1.48735755   1.29835474   1.17461997\n",
            "   1.10658572   1.0845462    1.10233731   1.1573868    1.27126175\n",
            "   1.48008969   1.83093241   2.37268899   3.24023818   4.59657648\n",
            "   6.98213878  11.85165293  28.73246971 119.06965098 236.64107843\n",
            " 100.406296    34.3273495   16.44518694   9.32496273   6.15125189\n",
            "   4.27068048   3.13011382   2.36017226   1.85645969   1.52148339\n",
            "   1.31581698   1.21516564   1.18157637   1.18749928   1.1978593\n",
            "   1.19365301   1.19272375   1.23924483   1.39719288   1.70127172\n",
            "   2.19266221   3.00297846   4.39531544   6.82973656  11.60834673\n",
            "  27.46227129  98.55722165 178.13578242  60.93439342  25.82656051\n",
            "  13.71255036   8.50406003   5.71744346   3.94677969   2.84734506\n",
            "   2.13202918   1.67614652   1.40049688   1.28519492   1.29736103\n",
            "   1.3731792    1.43362592   1.43351913   1.37583235   1.2955237\n",
            "   1.28791557   1.41568098   1.70543838   2.19030459   3.01192526\n",
            "   4.53719563   7.620408    14.08841966  34.25235358 110.37955618\n",
            " 145.90779448  52.56139116  25.53563886  13.89239382   8.74463137\n",
            "   5.72272111   3.84662712   2.71322155   2.00903108   1.59018861\n",
            "   1.38301624   1.36287434   1.49705408   1.65947952   1.70595119\n",
            "   1.61981703   1.49461518   1.36070093   1.34078457   1.47312583\n",
            "   1.79150396   2.30681542   3.1667427    4.85339124   8.67306507\n",
            "  18.07152022  40.58978239 123.19889026 169.44759645  63.33666186\n",
            "  27.53827611  16.21568632   9.72397519   5.87792485   3.76994758\n",
            "   2.59615835   1.90802381   1.53520349   1.4024572    1.46758336\n",
            "   1.67178074   1.81983542   1.74364503   1.58850984   1.45022132\n",
            "   1.33270445   1.35216185   1.54018337   1.923842     2.49832275\n",
            "   3.34997546   4.96366364   9.24291027  26.23598867  54.4067906\n",
            " 157.07120903 219.80838897  87.00292998  37.82885378  20.24451793\n",
            "  10.71569288   5.83265852   3.60153535   2.44735292   1.81242046\n",
            "   1.49813655   1.41722769   1.5147441    1.68820496   1.70599201\n",
            "   1.52075216   1.37729309   1.28409267   1.23254156   1.32674334\n",
            "   1.60531828   2.06886925   2.65793465   3.44641852   4.85093791\n",
            "   8.84573066  29.7695323   72.84443155 130.3164474  236.64107843\n",
            " 138.5091012   54.66628978  25.03735028  11.03961632   5.49995787\n",
            "   3.35650782   2.31354451   1.75070647   1.48588781   1.43440155\n",
            "   1.5123184    1.5799753    1.45083649   1.25788697   1.16723952\n",
            "   1.1319738    1.1413797    1.30762753   1.66083434   2.14114893\n",
            "   2.68576591   3.40701611   4.63479379   8.03725375  24.95194731\n",
            "  68.40899112 163.65435926 236.64107843 181.20353228  87.77136123\n",
            "  29.7157173   10.89714917   5.06647847   3.141879     2.22235775\n",
            "   1.73291915   1.5029775    1.45932248   1.48997642   1.4505074\n",
            "   1.24596719   1.09200101   1.04662216   1.06812292   1.12593072\n",
            "   1.32845865   1.6824995    2.10653963   2.60083002   3.29130674\n",
            "   4.45885456   7.55843914  20.999095    72.19880781 158.29331522\n",
            " 232.51645543 236.55772631  99.44351096  27.89820852   9.95401527\n",
            "   4.6411275    2.99211462   2.20796129   1.77400065   1.56245999\n",
            "   1.50481524   1.48260893   1.36405682   1.16510667   1.05353201\n",
            "   1.0537255    1.09990147   1.18249515   1.39618742   1.69290321\n",
            "   2.05164475   2.50802156   3.20287085   4.45743347   7.50471322\n",
            "  18.2792883   56.88441376 156.93766756 236.64107843 226.27520151\n",
            "  64.73784084  24.36862523   8.79430096   4.30767296   2.90861243\n",
            "   2.24707061   1.87218833   1.68378417   1.60967325   1.54073902\n",
            "   1.39544236   1.22826238   1.13821779   1.14343687   1.18848916\n",
            "   1.28706374   1.4636316    1.6952989    2.00281229   2.48301938\n",
            "   3.22417196   4.60588912   7.70587861  17.08560615  48.18575924\n",
            " 176.57734251   0.         157.6175613   51.41699895  19.28981891\n",
            "   7.45725145   4.0201552    2.86153893   2.30434505   1.99272268\n",
            "   1.8272167    1.74021918   1.64881809   1.52133696   1.37850237\n",
            "   1.27347392   1.24904194   1.28019466   1.36162146   1.48538832\n",
            "   1.68221645   2.00463012   2.52197727   3.36978234   4.91392852\n",
            "   8.281731    16.61057075  47.01818893 121.19033509 180.17430008\n",
            " 195.15774216  44.60298173  15.24726499   6.49459786   3.77822794\n",
            "   2.7745944    2.29750659   2.03503711   1.88232579   1.77635075\n",
            "   1.6982694    1.61177087   1.46466372   1.33809263   1.28512287\n",
            "   1.29738994   1.35310824   1.46471192   1.68389622   2.06059312\n",
            "   2.64165377   3.58717737   5.31215217   8.82466685  16.88126893\n",
            "  50.98496451 122.71985519 236.64107843 173.5813858   34.92351999\n",
            "  12.80052822   6.03728765   3.63677653   2.67395266   2.20461741\n",
            "   1.94242581   1.77791011   1.66652939   1.59754413   1.51489325\n",
            "   1.39205446   1.27629347   1.23129188   1.25038325   1.31893582\n",
            "   1.47706309   1.76586264   2.21270686   2.89241477   3.99145752\n",
            "   5.97407489   9.75254325  18.48006126  47.76038717 164.51647992\n",
            "   0.         140.11271909  32.76335155  12.17833472   6.15938347\n",
            "   3.77417803   2.67810933   2.12582406   1.81171182   1.62184812\n",
            "   1.49719882   1.41209016   1.328746     1.23503618   1.16199051\n",
            "   1.15661642   1.22177401   1.35880252   1.5929291    1.96635146\n",
            "   2.53134381   3.40281824   4.78630273   7.13921525  11.39570369\n",
            "  22.76991419  60.9122507  168.97751683 236.64107843 154.81120172\n",
            "  36.85609891  13.83592928   7.16761081   4.27779687   2.91329931\n",
            "   2.1938989    1.78467943   1.53432721   1.37504753   1.27139271\n",
            "   1.18722732   1.12569608   1.10873381   1.16568417   1.30226779\n",
            "   1.52880197   1.87380333   2.38742745   3.15894753   4.37645595\n",
            "   6.231417     9.16369624  14.70224602  30.36508949  82.77260945\n",
            " 236.64107843 236.64107843 225.30242222  49.67039492  18.80234072\n",
            "   9.54575202   5.54133342   3.59783439   2.57464996   1.98019467\n",
            "   1.61888197   1.3917424    1.25284989   1.17445026   1.15214826\n",
            "   1.1921596    1.31900994   1.54652712   1.89036633   2.40510845\n",
            "   3.15793776   4.30311133   6.08360091   8.73836395  12.77144041\n",
            "  21.70541165  50.21109315 112.29741213 236.64107843   0.\n",
            " 236.64107843  77.69253318  32.76753336  14.8873885    8.49040907\n",
            "   5.30450779   3.58346517   2.62160084   2.05258235   1.69947898\n",
            "   1.49412412   1.40427549   1.41092613   1.51587502   1.72662628\n",
            "   2.07242364   2.60303376   3.39820808   4.53489782   6.28837519\n",
            "   9.07401897  13.1405202   20.11378056  37.37544932  86.18401647\n",
            " 175.34769906   0.           0.           0.         163.88839842\n",
            "  62.280937    27.60194068  15.20177243   9.27321396   6.02892207\n",
            "   4.30066813   3.29032212   2.69483609   2.37409959   2.24346498\n",
            "   2.25495636   2.41214566   2.73916037   3.23365669   3.98417968\n",
            "   5.13144664   6.71083191   9.36368908  13.67015872  20.67026646\n",
            "  33.82732978  70.68392066 161.35375744 232.74763719   0.\n",
            "   0.           0.         172.59532117 153.06707623  56.10735371\n",
            "  27.81194868  15.93565712  10.26496528   7.17026991   5.60511823\n",
            "   4.68935055   4.23996882   4.05708993   4.07932086   4.34282084\n",
            "   4.80645782   5.40945982   6.4148758    7.96833374  10.34367382\n",
            "  14.35058124  20.89681544  34.11977946  56.58289574 143.26767226\n",
            " 186.44545576 236.64107843   0.           0.           0.\n",
            "   0.           0.         151.6799176   50.92165323  25.3797315\n",
            "  16.63069712  11.85687625   9.71736209   8.27652269   7.37888044\n",
            "   7.10308363   7.17592823   7.59954266   8.55325741   9.58629434\n",
            "  11.47938055  14.41724712  18.7571868   25.09362114  40.10194512\n",
            "  75.34915488 107.73952358 234.47110908 236.64107843   0.\n",
            "   0.           0.           0.           0.           0.\n",
            " 234.44304599 173.0004086  100.66813656  64.81338481  51.56135314\n",
            "  42.70183749  35.0843135   28.57753741  26.64831655  25.12212187\n",
            "  23.13601566  24.26810179  26.43920471  31.9393469   43.20088045\n",
            "  60.62661857 100.91712809 159.27505023 178.62214885 236.64107843\n",
            "   0.           0.           0.           0.        ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Random Forest**"
      ],
      "metadata": {
        "id": "TKQ1x2b4FhHW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "id": "_YmbEFpB1GDl",
        "outputId": "986af9e8-e233-4756-c99a-42660dae0a40"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OneVsRestClassifier(estimator=Pipeline(steps=[('randomforestclassifier',\n",
              "                                               RandomForestClassifier(random_state=42))]))"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneVsRestClassifier(estimator=Pipeline(steps=[(&#x27;randomforestclassifier&#x27;,\n",
              "                                               RandomForestClassifier(random_state=42))]))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneVsRestClassifier</label><div class=\"sk-toggleable__content\"><pre>OneVsRestClassifier(estimator=Pipeline(steps=[(&#x27;randomforestclassifier&#x27;,\n",
              "                                               RandomForestClassifier(random_state=42))]))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;randomforestclassifier&#x27;,\n",
              "                 RandomForestClassifier(random_state=42))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "rf_classifier = OneVsRestClassifier(\n",
        "    make_pipeline(RandomForestClassifier(random_state=42))\n",
        ")\n",
        "rf_classifier.fit(X_train_prepared, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "RnkZ6tds1LTt",
        "outputId": "f6da70b4-5acf-4c47-a447-a378cc552725"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1315    0    5    2    1    1    4    1   14    0]\n",
            " [   0 1520   15   11    2   11    2    3   36    0]\n",
            " [   1    0 1327    7    4    1    4    3   30    3]\n",
            " [   1    0   11 1359    1    9    1    9   35    7]\n",
            " [   1    0    9    1 1236    1    8    1    9   29]\n",
            " [   2    0    1   22    0 1221    8    0   18    1]\n",
            " [   4    0    2    0   10   11 1356    0   13    0]\n",
            " [   7    1   19    4    8    2    0 1412   11   39]\n",
            " [   1    0   11   11    1    4    3    4 1319    3]\n",
            " [   5    4    5   16   23    7    0   20   31 1309]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98      1343\n",
            "           1       1.00      0.95      0.97      1600\n",
            "           2       0.94      0.96      0.95      1380\n",
            "           3       0.95      0.95      0.95      1433\n",
            "           4       0.96      0.95      0.96      1295\n",
            "           5       0.96      0.96      0.96      1273\n",
            "           6       0.98      0.97      0.97      1396\n",
            "           7       0.97      0.94      0.96      1503\n",
            "           8       0.87      0.97      0.92      1357\n",
            "           9       0.94      0.92      0.93      1420\n",
            "\n",
            "    accuracy                           0.96     14000\n",
            "   macro avg       0.96      0.96      0.96     14000\n",
            "weighted avg       0.96      0.96      0.96     14000\n",
            "\n",
            "Accuracy: 0.9552857142857143\n",
            "Precision: 0.9565594814651489\n",
            "Recall: 0.9552857142857143\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn import metrics\n",
        "\n",
        "y_train_pred =  rf_classifier.predict(X_test_prepared)\n",
        "\n",
        "\n",
        "print(confusion_matrix(y_test, y_train_pred ))\n",
        "\n",
        "\n",
        "print(classification_report(y_test, y_train_pred ))\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_train_pred ))\n",
        "print(\"Precision:\",metrics.precision_score(y_test, y_train_pred,average='weighted'))\n",
        "print(\"Recall:\",metrics.recall_score(y_test, y_train_pred,average='weighted'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "NB = BernoulliNB()\n",
        "\n",
        "NB.fit(X_train_prepared, y_train)\n",
        "\n",
        "prediction = NB.predict(X_test_prepared)\n",
        "\n",
        "labels = np.unique(y_test)\n",
        "print(confusion_matrix(y_test, prediction))\n",
        "\n",
        "#Overall, how often is the classifier correct?\n",
        "\n",
        "print(classification_report(y_test, prediction))\n",
        "\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, prediction))\n",
        "print(\"Precision:\",metrics.precision_score(y_test, prediction,average='weighted'))\n",
        "print(\"Recall:\",metrics.recall_score(y_test, prediction,average='weighted'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDWWFGo5FAED",
        "outputId": "2c8104d4-8771-4353-f40e-860d71ee679e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1198    1    7    3    2   54   43    1   31    3]\n",
            " [   0 1525    6    6    1   17    4    1   38    2]\n",
            " [  17   28 1131   45   25    7   55   14   53    5]\n",
            " [  10   32   63 1161    3   33   13   16   59   43]\n",
            " [   5    8    9    1 1014    6   26    3   23  200]\n",
            " [  24   21   11  176   34  911   27    5   36   28]\n",
            " [  16   38   25    1   20   31 1261    0    4    0]\n",
            " [   7   31   10    5   36    2    1 1277   30  104]\n",
            " [  14   68   19  100   12   49   12    5 1024   54]\n",
            " [  10   31   10   13  100    9    0   49   30 1168]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.89      0.91      1343\n",
            "           1       0.86      0.95      0.90      1600\n",
            "           2       0.88      0.82      0.85      1380\n",
            "           3       0.77      0.81      0.79      1433\n",
            "           4       0.81      0.78      0.80      1295\n",
            "           5       0.81      0.72      0.76      1273\n",
            "           6       0.87      0.90      0.89      1396\n",
            "           7       0.93      0.85      0.89      1503\n",
            "           8       0.77      0.75      0.76      1357\n",
            "           9       0.73      0.82      0.77      1420\n",
            "\n",
            "    accuracy                           0.83     14000\n",
            "   macro avg       0.84      0.83      0.83     14000\n",
            "weighted avg       0.84      0.83      0.83     14000\n",
            "\n",
            "Accuracy: 0.8335714285714285\n",
            "Precision: 0.8359834028555766\n",
            "Recall: 0.8335714285714285\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "model = SVC(kernel='linear', random_state=42)  # Specifica il kernel (lineare, RBF, polinomiale, ecc.)\n",
        "model.fit(X_train_prepared, y_train)\n",
        "\n",
        "# Predizione dei risultati\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "labels = np.unique(y_test)\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred,labels=labels))\n",
        "\n",
        "\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
        "print(\"Precision:\",metrics.precision_score(y_test, y_pred,average='weighted'))\n",
        "print(\"Recall:\",metrics.recall_score(y_test, y_pred,average='weighted'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y63aYO95JCXG",
        "outputId": "e586d41c-3263-49a6-aa86-9af699668dc8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SVC was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1315    0    4    2    4    1    7    1    8    1]\n",
            " [   1 1309    2   14    2    1    1    2  267    1]\n",
            " [  23   15 1074   54   39    0   38   14  116    7]\n",
            " [  14    3   11 1319    1   11    5    2   59    8]\n",
            " [   9    0    3    4 1189    0   11    1   13   65]\n",
            " [  99   13   11  208   34  385   34    1  463   25]\n",
            " [  18    2   21    2   25    5 1308    0   15    0]\n",
            " [  21    2   27  114   48    1    0 1173   39   78]\n",
            " [  16    4    3   21    4    1   10    2 1292    4]\n",
            " [  15    5    5   34   82    0    0   14   87 1178]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.98      0.92      1343\n",
            "           1       0.97      0.82      0.89      1600\n",
            "           2       0.93      0.78      0.85      1380\n",
            "           3       0.74      0.92      0.82      1433\n",
            "           4       0.83      0.92      0.87      1295\n",
            "           5       0.95      0.30      0.46      1273\n",
            "           6       0.93      0.94      0.93      1396\n",
            "           7       0.97      0.78      0.86      1503\n",
            "           8       0.55      0.95      0.70      1357\n",
            "           9       0.86      0.83      0.85      1420\n",
            "\n",
            "    accuracy                           0.82     14000\n",
            "   macro avg       0.86      0.82      0.81     14000\n",
            "weighted avg       0.86      0.82      0.82     14000\n",
            "\n",
            "Accuracy: 0.8244285714285714\n",
            "Precision: 0.860601158752679\n",
            "Recall: 0.8244285714285714\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMsr8M9yOij7ewY1A+PgW9F",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}